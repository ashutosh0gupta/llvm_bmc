AArch64 szymanski

{
	int64_t flag1;
	int64_t flag2;
	int64_t x;
	0:X1 = flag1;
	0:X2 = flag2;
	0:X3 = x;
	0:X10 = 3; (* LOOP BOUND *)
	1:X1 = flag1;
	1:X2 = flag2;
	1:X3 = x;
	1:X10 = 3; (* LOOP BOUND *)
}

P0           | P1         ;

MOV X5, #1   | MOV X5, #1 ;
MOV X6, #2   | MOV X6, #2 ;
MOV X7, #3   | MOV X7, #3 ;
MOV X8, #4   | MOV X8, #4 ;
MOV X9, #0   | MOV X9, #0 ;

LOOP0:       | LOOP1:     ;

STR X5, [X1] | STR X5, [X2] ;
DMB SY       | DMB SY       ;
LDR X4, [X2] | LDR X4, [X1] ;
(* No support for B.GE (3) *)
CMP X4, #3   | CMP X4, #3   ;
B.EQ EXIT1   | B.EQ EXIT2   ;
CMP X4, #4   | CMP X4, #4   ;
B.EQ EXIT1   | B.EQ EXIT2   ;

STR X7, [X1] | STR X7, [X2] ;
DMB SY       | DMB SY       ;
LDR X4, [X2] | LDR X4, [X1] ;
CMP X4, #1   | CMP X4, #1   ;
B.NE AFT_IF1 | B.NE AFT_IF2 ;
STR X6, [X1] | STR X6, [X2] ;
DMB SY       | DMB SY       ;
LDR X4, [X2] | LDR X4, [X1] ;
CMP X4, #4   | CMP X4, #4   ;
B.NE EXIT1   | B.NE EXIT2   ;

AFT_IF1:     | AFT_IF2:     ;
STR X8, [X1] | STR X8, [X2] ;
DMB SY       | DMB SY       ;
LDR X4, [X2] | LDR X4, [X1] ;
(* No support for B.GE (2) *)
CMP X4, #2   | CMP X4, #2   ;
B.EQ EXIT1   | B.EQ EXIT2   ;
CMP X4, #3   | CMP X4, #3   ;
B.EQ EXIT1   | B.EQ EXIT2   ;
CMP X4, #4   | CMP X4, #4   ;
B.EQ EXIT1   | B.EQ EXIT2   ;

STR X9, [X3] | STR X5, [X3] ;
LDR X4, [X3] | LDR X4, [X3] ;
DMB SY       | DMB SY       ;

LDR X4, [X2] | LDR X4, [X1] ;
(* No support for B.LT (2) *)
CMP X4, #1   | CMP X4, #1   ;
B.EQ FINAL1  | B.EQ FINAL2  ;
CMP X4, #0   | CMP X4, #0   ;
B.EQ FINAL1  | B.EQ FINAL2  ;
LDR X4, [X2] | LDR X4, [X1] ;
(* No support for B.GE (3) *)
CMP X4, #4   | CMP X4, #4   ;
B.EQ FINAL1  | B.EQ FINAL2  ;
B EXIT1      | B EXIT2      ;

FINAL1:      | FINAL2:      ;
STR X9, [X1] | STR X9, [X2] ;

SUBS X10, X10, #1 | SUBS X10, X10, #1 ;
CMP X10, #0  | CMP X10, #0  ;
B.NE LOOP0   | B.NE LOOP1   ;

EXIT1:       | EXIT2:       ;

forall x = 1  \/ x = 0